{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def LeastSquare(regressor, response):\n",
    "    # use numpy.linalg.lstsq\n",
    "    # modify residual and singular value, eliminate the effect caused by data size\n",
    "    if regressor.shape[0] <= regressor.shape[1]:\n",
    "        raise ValueError(\"regressor size error, #datums <= #variables\")\n",
    "    \n",
    "    coe, res, rank, singular_value = np.linalg.lstsq(regressor, response, rcond=-1)\n",
    "    rms = res / (regressor.shape[0] - regressor.shape[1]) # residual mean square\n",
    "    return coe, rms, rank, singular_value\n",
    "\n",
    "def PCStd(data):\n",
    "    # data : numpy matrix\n",
    "    # return standard deviation of each principal component\n",
    "    if data.shape[0] < 2:\n",
    "        raise ValueError(\"data size error, variance of single datum is meaningless\")\n",
    "    \n",
    "    data -= data.mean(axis=0)\n",
    "    output = np.linalg.eigh(np.dot(data.T, data))[0][::-1]/(data.shape[0] - 1)\n",
    "    output = np.sqrt(output)\n",
    "    return output\n",
    "\n",
    "class LinearRegression():\n",
    "    def __init__(self, regressor, response, has_bias = True, regularizer = 10**-10):\n",
    "        self.SetData(regressor, response, has_bias)\n",
    "        self.SetRegularizer(regularizer)\n",
    "    \n",
    "    def SetData(self, regressor, response, has_bias):\n",
    "        if (regressor.ndim != 2) or (regressor.size == 0):\n",
    "            raise ValueError(\"regressor should be a non-empty numpy matrix\")\n",
    "        elif (response.ndim != 2) or (response.size == 0):\n",
    "            raise ValueError(\"response should be a non-empty numpy matrix\")\n",
    "        elif len(regressor) != len(response):\n",
    "            raise ValueError(\"len(regressor) != len(response)\")\n",
    "        \n",
    "        self.num_var = regressor.shape[1]\n",
    "        self.has_bias = has_bias\n",
    "        if self.has_bias:\n",
    "            self.regressor = np.append(regressor, np.ones((len(regressor), 1)), axis=1)\n",
    "        else:\n",
    "            self.regressor = regressor\n",
    "        \n",
    "        self.response = response\n",
    "    \n",
    "    def SetRegularizer(self, regularizer):\n",
    "        if regularizer < 0.:\n",
    "            self.regularizer = 0.\n",
    "            print(\"SetRegularizer error, regularizer must be non-negative, has been set to zero.\")\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "    \n",
    "    def MostUselesscAnalysis(self, drop=1):\n",
    "        gram = np.dot(self.regressor.T, self.regressor)\n",
    "        gram += self.regularizer * self.regressor.shape[0] * np.identity(self.regressor.shape[1])\n",
    "        projected = np.dot(self.regressor.T, self.response)\n",
    "        is_leave = np.ones((gram.shape[0]), dtype=bool)\n",
    "        response_square = np.square(self.response).sum(axis=0)\n",
    "        for d in range(drop):\n",
    "            square_err = np.inf * np.ones((gram.shape[0]), dtype=bool)\n",
    "            for i in range(self.num_var):\n",
    "                if is_leave[i]:\n",
    "                    work_index = (is_leave * (np.arange(len(is_leave)) != i)).astype(bool)\n",
    "                    coe = np.linalg.solve(gram[work_index][:, work_index], projected[work_index])\n",
    "                    square_err[i] = (response_square\n",
    "                                     - (coe * projected[work_index]).sum(axis=0) \n",
    "                                     - self.regularizer * np.square(coe).sum(axis=0)\n",
    "                                    ).sum()\n",
    "            \n",
    "            is_leave[np.argmin(square_err)] = False\n",
    "        \n",
    "        rms = square_err.min()/(self.regressor.shape[0] - is_leave.sum())\n",
    "        coe = np.linalg.solve(gram[is_leave][:, is_leave], projected[is_leave])\n",
    "        \n",
    "        if self.has_bias:\n",
    "            return is_leave[:-1], coe[:-1], coe[-1].reshape(1, -1), rms\n",
    "        else:\n",
    "            return is_leave, coe, np.zeros((1, self.num_var)), rms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
